import pandas as pd
configfile: "./gene_pair_corrs.yaml"

# Add trailing /.
if not config["top_directory"].endswith("/"):
    config["top_directory"] += "/"
if not config["output_directory"].endswith("/"):
    config["output_directory"] += "/"
if not config["snakefile_dir"].endswith("/"):
    config["snakefile_dir"] += "/"
if not config["seurat_dir"].endswith("/"):
    config["seurat_dir"] += "/"

# Check if the singularity image exists.
if not os.path.exists(config["singularity_path"]):
    logger.info("Error, the singularity image does not exist.\n\nExiting.")
    exit("MissingSIFFile")

# Check if the Seurat file exists.
if not os.path.exists(config["seurat_dir"]):
    logger.info("Error, the seurat file does not exist.\n\nExiting.")
    exit("MissingSIFFile")

# Load donor list
donor_df = pd.read_csv(config["donor_list_path"], sep = "\t", header = None)
donor_list = list(donor_df[0])

# Define metrics
metrics = ['corr', 'std', 'pval', 'zscore']

# Define weight
weight = "unweighted"
if config["weight"]:
    weight = "weighted"

wildcard_constraints:
    n="[0-9]+"

rule all:
    input:  
        prioritized_genes = expand(config["output_directory"] + config["cohort"] + "/{gwas}_covCor_enrichments.xlsx",
        gwas = config["gwas"])

rule createDonorRds:
    input: 
        config["seurat_dir"] +  "{ct}.Qced.Normalized.SCs.Rds"
    output:
        counts = temp(config["output_directory"] + config["cohort"] + "/normalized-counts-{ct}-top-{n}.tsv.gz"),
        weights = temp(expand(config["output_directory"] + config["cohort"] + "/donor_weight/correlation-weight-{donor}-{ct}-top-{n}.tsv.gz",donor=donor_list, allow_missing=True)),
        barcodes = temp(expand(config["output_directory"] + config["cohort"] + "/donor_barcodes/barcodes-{donor}-{ct}-top-{n}.tsv.gz", donor=donor_list, allow_missing=True)),
        donor_genes = expand(config["output_directory"] + config["cohort"] + "/donor_gene_list/filtered-genes-{donor}-{ct}-top-{n}.tsv.gz", donor=donor_list, allow_missing=True),
        gene_list = config["output_directory"] + config["cohort"] + "/gene_list/{ct}-top-{n}-gene-list.tsv.gz",
        donor_list = temp(config["output_directory"] + config["cohort"] + "/donor_list/{ct}-top-{n}-donor-list.tsv.gz")
    resources:
        mem_per_thread_gb =  lambda wildcards, attempt: attempt * config["create_donor"]["create_donor_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["create_donor"]["create_donor_time"]]
    threads: config["create_donor"]["create_donor_threads"]  
    params:
        out = config["output_directory"],
        top = config["top_directory"],
        sif = config["singularity_path"],
        scripts = config["snakefile_dir"]+"scripts/",
        cohort = config["cohort"],
        genes = config["gene_list_path"],
        donors = config["donor_list_path"]
    shell:
        """
        singularity exec --bind {params.top} {params.sif} Rscript {params.scripts}process_rds.R \
            --celltype {wildcards.ct} \
            --cohort {params.cohort} \
            --genelist {params.genes} \
            --n {wildcards.n} \
            --donors {params.donors} \
            --genepath {output.gene_list} \
            --donorpath {output.donor_list} \
            --input {input} \
            --output {params.out}
        """

rule calculate_correlations:
    input:
        counts = config["output_directory"] + config["cohort"] + "/normalized-counts-{ct}-top-{n}.tsv.gz",
        weights = config["output_directory"] + config["cohort"] + "/donor_weight/correlation-weight-{donor}-{ct}-top-{n}.tsv.gz",
        gene_list = config["output_directory"] + config["cohort"] + "/donor_gene_list/filtered-genes-{donor}-{ct}-top-{n}.tsv.gz",
        barcodes = config["output_directory"] + config["cohort"] + "/donor_barcodes/barcodes-{donor}-{ct}-top-{n}.tsv.gz" 
    output:
        corr = config["output_directory"] + config["cohort"] + "/{donor}-{ct}-top-{n}-{method}-{weight}.tsv.gz"
    resources:
        mem_per_thread_gb =  lambda wildcards, attempt: attempt * config["process_donor"]["process_donor_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["process_donor"]["process_donor_time"]]
    threads: config["process_donor"]["process_donor_threads"] 
    params:
        top = config["top_directory"],
        sif = config["singularity_path"],
        scripts = config["snakefile_dir"]+"scripts/",
        cohort = config["cohort"],
        out = config["output_directory"], 
        metadata = "--metadata True" if config["metadata"] else "",
        weighted = config["weight"]
    shell:
        """
        singularity exec --bind {params.top} {params.sif} python {params.scripts}calculate_correlation.py \
            --counts {input.counts} \
            --method {wildcards.method} \
            --weight {params.weighted} {input.weights}\
            --cell_barcodes {input.barcodes} \
            --gene_list {input.gene_list} \
            --output {output.corr}
        """
        
rule aggregate_final_results:
    input:
        donor_list = config["output_directory"] + config["cohort"] + "/donor_list/{ct}-top-{n}-donor-list.tsv.gz",
        corr = expand(config["output_directory"] + config["cohort"] + "/{donor}-{ct}-top-{n}-{method}-{weight}.tsv.gz",donor=donor_list,allow_missing=True)
    output:
        corr = temp(config["output_directory"] + config["cohort"] + "/combined-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz"),
        std = temp(config["output_directory"] + config["cohort"] + "/combined-std-{ct}-top-{n}-{method}-{weight}.tsv.gz"),
        pval = temp(config["output_directory"] + config["cohort"] + "/combined-pval-{ct}-top-{n}-{method}-{weight}.tsv.gz"),
        zscore = temp(config["output_directory"] + config["cohort"] + "/combined-zscore-{ct}-top-{n}-{method}-{weight}.tsv.gz")
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["aggregate_metrics"]["aggregate_metrics_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["aggregate_metrics"]["aggregate_metrics_time"]]
    threads: config["aggregate_metrics"]["aggregate_metrics_threads"] 
    params:
        top = config["top_directory"],
        sif = config["singularity_path"],
        scripts = config["snakefile_dir"]+"scripts/",
        out = config["output_directory"],
        cohort = config["cohort"],
    shell:
        """
        singularity exec --bind {params.top} {params.sif} python {params.scripts}aggregate_metrics.py \
            --celltype {wildcards.ct} \
            --cohort {params.cohort} \
            --n {wildcards.n} \
            --method {wildcards.method} \
            --weight {wildcards.weight} \
            --input {input.donor_list} {params.out} \
            --output {output.corr} {output.std} {output.pval} {output.zscore}
        """
        
rule quality_control:
    input:
        donor_list = config["output_directory"] + config["cohort"] + "/donor_list/{ct}-top-{n}-donor-list.tsv.gz",
        corr = config["output_directory"] + config["cohort"] + "/combined-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz"
    output:
        donor_list = config["output_directory"] + config["cohort"] + "/donor_list/{ct}-top-{n}-{method}-{weight}-donor-list-updated.tsv.gz",
        corr = config["output_directory"] + config["cohort"] + "/outliers-removed-combined-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz",
        outliers = config["output_directory"] + config["cohort"] + "/outliers-{ct}-top-{n}-{method}-{weight}.tsv.gz"
        #qc0 = config["output_directory"] + config["cohort"] + "/plots/qc0-pc1-pc2-{ct}-top-{n}-{method}-{weight}.png",
        #qc1 = config["output_directory"] + config["cohort"] + "/plots/qc1-pc1-pc2-{ct}-top-{n}-{method}-{weight}.png"
    params:
        top = config["top_directory"],
        sif = config["singularity_path"],
        scripts = config["snakefile_dir"] + "scripts/"
    shell:
        """
        singularity exec --bind {params.top} {params.sif} python {params.scripts}sample_quality_control.py \
            --input {input.corr} \
            --output "" "" {output.outliers} {output.corr} \
            --donor_list {input.donor_list} \
            --donor_list_updated {output.donor_list}
        """

rule create_matrix:
    input: 
        donor_list = config["output_directory"] + config["cohort"] + "/donor_list/{ct}-top-{n}-{method}-{weight}-donor-list-updated.tsv.gz",
        gene_list = config["output_directory"] + config["cohort"] + "/gene_list/{ct}-top-{n}-gene-list.tsv.gz",
        corr = config["output_directory"] + config["cohort"] + "/outliers-removed-combined-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz"
    output:
        gene_list = config["output_directory"] + config["cohort"] + "/gene_list/{meta_analysis}-corr-{ct}-top-{n}-{method}-{weight}-gene-list-updated.tsv.gz",
        corr = config["output_directory"] + config["cohort"] + "/matrix-corr-{meta_analysis}-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz",
        pval = config["output_directory"] + config["cohort"] + "/matrix-pval-{meta_analysis}-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["create_matrix"]["create_matrix_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["create_matrix"]["create_matrix_time"]]
    threads: config["create_matrix"]["create_matrix_threads"]
    params:
        top = config["top_directory"],
        sif = config["singularity_path"],
        scripts = config["snakefile_dir"] + "scripts/",
        out = config["snakefile_dir"] + "output/" + config["cohort"]
    shell:
        """ 
        singularity exec --bind {params.top} {params.sif} python {params.scripts}create_matrix.py \
            --meta_analysis {wildcards.meta_analysis} \
            --donor_list {input.donor_list} \
            --gene_list {input.gene_list} \
            --gene_list_updated {output.gene_list} \
            --celltype {wildcards.ct} \
            --n {wildcards.n} \
            --input {input.corr} \
            --output {params.out} {output.corr} {output.pval}
        """
        
rule aggregate_gwas_genes:
    input:
        sum_stats = config["sum_stats_path"],
        annotation = config["annotation_path"]
    output:
        aggregated_genes = config["output_directory"] + config["cohort"] + "/pascalX/{gwas}.txt"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["aggregate_gwas_genes"]["aggregate_gwas_genes_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["aggregate_gwas_genes"]["aggregate_gwas_genes_time"]]
    threads: config["aggregate_gwas_genes"]["aggregate_gwas_genes_threads"]
    params:
        top = config["top_directory"],
        sif = config["singularity_path_downstreamer"],
        scripts = config["snakefile_dir"] + "scripts/",
        threads = config["threads"],
        rscol = config["rscol"],
        pcol = config["pcol"],
        window = config["window"],
        input = config["output_directory"] + "input/Downstreamer/"
    shell:
        """
        singularity exec --bind {params.top} {params.sif} python3 {params.scripts}runRealGWAS.py \
            --refpanel {params.input}1kGP_high_coverage/1kGP_high_coverage_Illumina \
            --gwas {input.sum_stats}
            --annotation {input.annotation}
            --threads {params.threads}
            --outfile {output.aggregated_genes}
            --rscol {params.rscol}
            --pcol {params.pcol} \
            --window {params.window}
        """
        
rule eigenDecompose_matrix:
    input:
        corr = config["output_directory"] + config["cohort"] + "/matrix-corr-{meta_analysis}-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz",
        annotation = config["snakefile_dir"] + "input/Downstreamer/LimixAnnotationFile.txt"
    output:
        eigenVec = config["output_directory"] + config["cohort"] + "/EigVec-{meta_analysis}-{ct}-top-{n}-{method}-{weight}.txt",
        eigenVal = config["output_directory"] + config["cohort"] +"/EigVal-{meta_analysis}-{ct}-top-{n}-{method}-{weight}.txt",
        #exp_var: config["output_directory"] + config["cohort"] +"/{ct}-subset-eigenVec-explained-variance.png"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["eigendecompose"]["eigendecompose_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["eigendecompose"]["eigendecompose_time"]]
    threads: config["eigendecompose"]["eigendecompose_threads"]
    params:
        top = config["top_directory"],
        sif = config["singularity_path_downstreamer"],
        scripts = config["snakefile_dir"] + "scripts/",
    shell:
        """
        singularity exec --bind {params.top} {params.sif} python {params.scripts}eigendecomposeCorr.py \
            --input {input.corr} {input.annotation} \
            --output "" {output.eigenVec} {output.eigenVal}
        """
        
rule reformat_eigenVec:
    input:
        eigenVec = config["output_directory"] + config["cohort"] + "/EigVec-{meta_analysis}-{ct}-top-{n}-{method}-{weight}.txt"
    output:
        config["output_directory"] + config["cohort"] + "/EigVec-{meta_analysis}-{ct}-top-{n}-{method}-{weight}.datg",
        config["output_directory"] + config["cohort"] + "/EigVec-{meta_analysis}-{ct}-top-{n}-{method}-{weight}.cols.txt.gz",
        config["output_directory"] + config["cohort"] + "/EigVec-{meta_analysis}-{ct}-top-{n}-{method}-{weight}.rows.txt.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["reformat_eigenVec"]["reformat_eigenVec_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["reformat_eigenVec"]["reformat_eigenVec_time"]]
    threads: config["reformat_eigenVec"]["reformat_eigenVec_threads"]
    params:
        top = config["top_directory"],
        sif = config["singularity_path_downstreamer"],
        scripts = config["snakefile_dir"] + "scripts/",
        depict2 = config["depict2_path"],
        out_dir = config["output_directory"],
        memory = "30G",
        cores = 1
    shell:
        """
        java -Xmx{params.memory} -XX:ParallelGCThreads={params.cores} -jar {params.depict2} \
        -m CONVERT_TXT \
        -g {input.eigenVec} \
        -o {params.out_dir}/ \
        -tgn 
        """
rule gene_prioritisation:
    input:
        gwas = config["output_directory"] + config["cohort"] + "/pascalX/{gwas}.txt", 
        genes = config["human_b37"],
        covariates = config["covariates"],
        converted_eigVec = expand(config["output_directory"] + config["cohort"] + "/EigVec-"+ "{meta_analysis}-{ct}-top-{n}-{method}-{weight}.datg",
                      meta_analysis = config["meta-analysis"],
                      ct = config["cell_type"],
                      n = config["n_genes"],
                      method = config["method"],
                      weight = weight)
    output:
        prioritized_genes = config["output_directory"] + config["cohort"] + "/{gwas}_covCor_enrichments.xlsx" 
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["gene_prioritisation"]["gene_prioritisation_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["gene_prioritisation"]["gene_prioritisation_time"]]
    threads: config["gene_prioritisation"]["gene_prioritisation_threads"]   
    params:
        top = config["top_directory"],
        sif = config["singularity_path_downstreamer"],
        scripts = config["snakefile_dir"] + "scripts/",
        memory = 50,
        depict2 = config["depict2_path"],
        output = config["output_directory"] + config["cohort"], 
        input = config["output_directory"] + "input/Downstreamer/",
        ct = config["cell_type"],
        meta_analysis = config["meta-analysis"],
        n = config["n_genes"],
        method = config["method"],
        weight = "weighted"if config["weight"] else "unweighted"
    shell:
        """
        java -Djava.util.concurrent.ForkJoinPool.common.parallelism=16 -Xmx{params.memory} -Xms{params.memory} -jar {params.depict2} \
        --mode ENRICH \
        --gwas {input.gwas} \
        --geneCorrelations {params.input}permutationGeneCor/geneCorForceNormalchr_ \
        --output {params.output}/{wildcards.gwas}_keygenes_covCor \
        --genes {input.genes} \
        --expressionEigenVectors {params.ct}={params.output}/EigVec-{params.meta_analysis}-{params.ct}-top-{params.n}-{params.method}-{params.weight} \
        --covariates {input.covariates} \
        --eh \
        -t 8 \
        --forceNormalGenePvalues \
        --jblas
        """