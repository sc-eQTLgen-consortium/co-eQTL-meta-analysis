configfile: "./gene_pair_corrs.yaml"

import pandas as pd
import os

out_dir = config["output_directory"]
top_dir = config["top_directory"]
simg_dir = config["singularity_path"]
snake_dir = config["snakefile_path"]
scripts_dir = snake_dir+"scripts/"
wg3_dir = config["wg3_path"]
cohort = config["cohort"]
wg3_dir = f"{wg3_dir}/{cohort}/input/L1/"

cell_types = config["cell_type"]
gene_list = config["gene_list_path"]

donor_file_path = f"{snake_dir}/donor_data/{cohort}_{cell_types}_donor_list.tsv"
donor_file_path = donor_file_path.replace(" ","")
print(f"Pipeline is being run for {cell_types} cells.")

if(os.path.exists(donor_file_path)):
    donors = pd.read_csv(donor_file_path, sep='\t')
    donors_list = [i for i in donors['filt_labels']]
    original_donor_ids = [i for i in donors['original_labels']]
    metrics = ['corr','pval','zscore']

    rule all:
        input:
            #expand(out_dir+cohort+"/"+"corr"+"-"+"{cell_type}"+"-"+"{donor}"+"-pearson-weighted.tsv.gz", cell_type=cell_types,donor=donors_list)
            expand(out_dir+cohort+"/{cohort}-combined-{metric}-{cell_type}-top-1000-pearson-weighted.tsv.gz", cohort=cohort,metric=metrics,cell_type=cell_types)
        output:
            touch(out_dir+cohort+"-"+cell_types+"-done.txt")

    rule createDonorRds:
        resources:
            mem_per_thread_gb = lambda wildcards, attempt: attempt * config["create_donor"]["create_donor_memory"]
        output:
            temp(expand(out_dir+cohort+"/donor_rds/{cell_type}-{donor}.rds", cell_type=cell_types,donor=donors_list))
        shell:
            """
            mkdir -p {out_dir}
            mkdir -p {out_dir}{cohort}
            mkdir -p {out_dir}{cohort}/donor_rds
            singularity exec --bind {top_dir} {simg_dir} Rscript {scripts_dir}create_donor_rds.R {cell_types} {cohort} {wg3_dir} {out_dir} {gene_list}
            """

    rule calculate_correlations:
        resources:
            mem_per_thread_gb = lambda wildcards, attempt: attempt * config["process_donor"]["process_donor_memory"]
        input:
            out_dir+cohort+"/donor_rds/{cell_type}-{donor}.rds"
        output:
            temp(out_dir+cohort+"/corr-"+"{cell_type}"+"-"+"{donor}"+"-pearson-weighted.tsv.gz"),
            temp(out_dir+cohort+"/pval-"+"{cell_type}"+"-"+"{donor}"+"-pearson-weighted.tsv.gz"),
            temp(out_dir+cohort+"/zscore-"+"{cell_type}"+"-"+"{donor}"+"-pearson-weighted.tsv.gz")
        params:
            ct = lambda wildcards: f"{wildcards.cell_type}",
            d = lambda wildcards: f"{wildcards.donor}",
            rds_path = lambda wildcards: (f"{out_dir}{cohort}/donor_rds/").replace(" ",""),
            gene_list = lambda wildcards: (f"{snake_dir}/gene_lists/{cohort}-{wildcards.cell_type}-genes.tsv").replace(" ","")
        shell:
            """
            singularity exec --bind {top_dir} {simg_dir} Rscript {scripts_dir}process_donor_rds.R {params.ct} {cohort} {params.d} {params.gene_list} {params.rds_path} {out_dir} {gene_list}
            """

    rule aggregate_final_results:
        resources:
            mem_per_thread_gb = lambda wildcards, attempt: attempt * config["aggregate_metrics"]["aggregate_metrics_memory"]
        input:
            expand(out_dir+cohort+"/"+"{{metric}}"+"-"+"{cell_type}"+"-"+"{donor}"+"-pearson-weighted.tsv.gz", cell_type=cell_types,donor=donors_list)
        output:
            out_dir+cohort+"/{cohort}-combined-{metric}-{cell_type}-top-1000-pearson-weighted.tsv.gz"
        params:
            ct = lambda wildcards: f"{wildcards.cell_type}",
            m = lambda wildcards: f"{wildcards.metric}",
            coh = lambda wildcards: f"{wildcards.cohort}",
            list_of_donors = (f"{donors_list}").replace(" ",""),
            original_ids = (f"{original_donor_ids}").replace(" ","")
        shell:
            """
            singularity exec --bind {top_dir} {simg_dir} python {scripts_dir}aggregate_metrics.py {params.list_of_donors} {params.original_ids} {params.ct} {params.m} {params.coh} {output} {out_dir}{cohort}
            """

else:
    print("Donor list file is being generated for subsequent runs of the pipeline.")
    print(f"Pipeline is being run for {cell_types} cells.")

    rule all:
        input:
            snake_dir+"gene_lists/"+cohort+"_"+cell_types+"_genes.tsv",
            snake_dir+"donor_data/"+cohort+"_"+cell_types+"_donor_list.tsv"
        output:
            touch(out_dir+cohort+"_"+cell_types+"_step1_done.txt")

    rule makeDonorLists:
        resources:
            mem_per_thread_gb = lambda wildcards, attempt: attempt * config["donor_list"]["donor_list_memory"]
        output:
            snake_dir+"donor_data/"+cohort+"_"+cell_types+"_donor_list.tsv"
        params:
            donor_data_path = (f"{snake_dir}/donor_data/").replace(" ",""),
            donor_rds_out_path = (f"{scripts_dir}donor_ids.R").replace(" ",""),
            gene_lists_out_path = (f"{snake_dir}/gene_lists/").replace(" ",""),
        shell:
            """
            mkdir -p {snake_dir}/donor_data
            mkdir -p {snake_dir}/gene_lists
            singularity exec --bind {top_dir} {simg_dir} Rscript {params.donor_rds_out_path} {cell_types} {cohort} {wg3_dir} {params.donor_data_path} {params.gene_lists_out_path} {gene_list}
            """

