import pandas as pd
configfile: "./gene_pair_corrs.yaml"

# Add trailing /.
if not config["top_directory"].endswith("/"):
    config["top_directory"] += "/"
if not config["output_directory"].endswith("/"):
    config["output_directory"] += "/"
if not config["snakefile_dir"].endswith("/"):
    config["snakefile_dir"] += "/"
if not config["seurat_dir"].endswith("/"):
    config["seurat_dir"] += "/"

# Check if the singularity image exists.
if not os.path.exists(config["singularity_path"]):
    logger.info("Error, the singularity image does not exist.\n\nExiting.")
    exit("MissingSIFFile")

# Check if the Seurat file exists.
if not os.path.exists(config["seurat_dir"]):
    logger.info("Error, the seurat file does not exist.\n\nExiting.")
    exit("MissingSIFFile")

# Load donor list
donor_df = pd.read_csv(config["donor_list_path"], sep = "\t", header = None)
donor_list = list(donor_df[0])

# Define metrics
metrics = ['corr', 'std', 'pval', 'zscore']

# Define weight
weight = "unweighted"
if config["weight"]:
    weight = "weighted"

wildcard_constraints:
    n="[0-9]+"

rule all:
    input:  
        corr = expand(config["output_directory"] + config["cohort"] + "/matrix-corr-{meta_analysis}-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz",
                      meta_analysis = config["meta-analysis"],
                      ct = config["cell_type"],
                      n = config["n_genes"],
                      method = config["method"],
                      weight = weight),
        pval = expand(config["output_directory"] + config["cohort"] + "/matrix-pval-{meta_analysis}-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz",
                      meta_analysis = config["meta-analysis"],
                      ct = config["cell_type"],
                      n = config["n_genes"],
                      method = config["method"],
                      weight = weight)

rule createDonorRds:
    input: 
        config["seurat_dir"] +  "{ct}.Qced.Normalized.SCs.Rds"
    output:
        counts = config["output_directory"] + config["cohort"] + "/normalized-counts-{ct}-top-{n}.tsv.gz",
        weights = expand(config["output_directory"] + config["cohort"] + "/donor_weight/correlation-weight-{donor}-{ct}-top-{n}.tsv.gz",donor=donor_list, allow_missing=True),
        barcodes = expand(config["output_directory"] + config["cohort"] + "/donor_barcodes/barcodes-{donor}-{ct}-top-{n}.tsv.gz", donor=donor_list, allow_missing=True),
        donor_genes = expand(config["output_directory"] + config["cohort"] + "/donor_gene_list/filtered-genes-{donor}-{ct}-top-{n}.tsv.gz", donor=donor_list, allow_missing=True),
        gene_list = config["output_directory"] + config["cohort"] + "/gene_list/{ct}-top-{n}-gene-list.tsv.gz",
        donor_list = config["output_directory"] + config["cohort"] + "/donor_list/{ct}-top-{n}-donor-list.tsv.gz"
    resources:
        mem_per_thread_gb =  lambda wildcards, attempt: attempt * config["create_donor"]["create_donor_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["create_donor"]["create_donor_time"]]
    threads: config["create_donor"]["create_donor_threads"]  
    params:
        out = config["output_directory"],
        top = config["top_directory"],
        sif = config["singularity_path"],
        scripts = config["snakefile_dir"]+"scripts/",
        cohort = config["cohort"],
        genes = config["gene_list_path"],
        donors = config["donor_list_path"]
    shell:
        """
        singularity exec --bind {params.top} {params.sif} Rscript {params.scripts}process_rds.R \
            --celltype {wildcards.ct} \
            --cohort {params.cohort} \
            --genelist {params.genes} \
            --n {wildcards.n} \
            --donors {params.donors} \
            --genepath {output.gene_list} \
            --donorpath {output.donor_list} \
            --input {input} \
            --output {params.out}
        """

rule calculate_correlations:
    input:
        counts = config["output_directory"] + config["cohort"] + "/normalized-counts-{ct}-top-{n}.tsv.gz",
        weights = config["output_directory"] + config["cohort"] + "/donor_weight/correlation-weight-{donor}-{ct}-top-{n}.tsv.gz",
        gene_list = config["output_directory"] + config["cohort"] + "/donor_gene_list/filtered-genes-{donor}-{ct}-top-{n}.tsv.gz",
        barcodes = config["output_directory"] + config["cohort"] + "/donor_barcodes/barcodes-{donor}-{ct}-top-{n}.tsv.gz" 
    output:
        corr = config["output_directory"] + config["cohort"] + "/{donor}-{ct}-top-{n}-{method}-{weight}.tsv.gz"
    resources:
        mem_per_thread_gb =  lambda wildcards, attempt: attempt * config["process_donor"]["process_donor_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["process_donor"]["process_donor_time"]]
    threads: config["process_donor"]["process_donor_threads"] 
    params:
        top = config["top_directory"],
        sif = config["singularity_path"],
        scripts = config["snakefile_dir"]+"scripts/",
        cohort = config["cohort"],
        out = config["output_directory"], 
        metadata = "--metadata True" if config["metadata"] else "",
        weighted = config["weight"]
    shell:
        """
        singularity exec --bind {params.top} {params.sif} python {params.scripts}calculate_correlation.py \
            --counts {input.counts} \
            --method {wildcards.method} \
            --weight {params.weighted} {input.weights}\
            --cell_barcodes {input.barcodes} \
            --gene_list {input.gene_list} \
            --output {output.corr}
        """

rule aggregate_final_results:
    input:
        donor_list = config["output_directory"] + config["cohort"] + "/donor_list/{ct}-top-{n}-donor-list.tsv.gz",
        corr = expand(config["output_directory"] + config["cohort"] + "/{donor}-{ct}-top-{n}-{method}-{weight}.tsv.gz",donor=donor_list,allow_missing=True)
    output:
        corr = config["output_directory"] + config["cohort"] + "/combined-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz",
        std = config["output_directory"] + config["cohort"] + "/combined-std-{ct}-top-{n}-{method}-{weight}.tsv.gz",
        pval = config["output_directory"] + config["cohort"] + "/combined-pval-{ct}-top-{n}-{method}-{weight}.tsv.gz",
        zscore = config["output_directory"] + config["cohort"] + "/combined-zscore-{ct}-top-{n}-{method}-{weight}.tsv.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["aggregate_metrics"]["aggregate_metrics_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["aggregate_metrics"]["aggregate_metrics_time"]]
    threads: config["aggregate_metrics"]["aggregate_metrics_threads"] 
    params:
        top = config["top_directory"],
        sif = config["singularity_path"],
        scripts = config["snakefile_dir"]+"scripts/",
        out = config["output_directory"],
        cohort = config["cohort"],
        out_dir = config["output_directory"]
    shell:
        """
        singularity exec --bind {params.top} {params.sif} python {params.scripts}aggregate_metrics.py \
            --celltype {wildcards.ct} \
            --cohort {params.cohort} \
            --n {wildcards.n} \
            --method {wildcards.method} \
            --weight {wildcards.weight} \
            --input {input.donor_list} {params.out} \
            --output {output.corr} {output.std} {output.pval} {output.zscore}
        """


rule create_matrix:
    input: 
        donor_list = config["output_directory"] + config["cohort"] + "/donor_list/{ct}-top-{n}-donor-list.tsv.gz",
        corr = config["output_directory"] + config["cohort"] + "/combined-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz"
    output:
        corr = config["output_directory"] + config["cohort"] + "/matrix-corr-{meta_analysis}-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz",
        pval = config["output_directory"] + config["cohort"] + "/matrix-pval-{meta_analysis}-corr-{ct}-top-{n}-{method}-{weight}.tsv.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["create_matrix"]["create_matrix_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["create_matrix"]["create_matrix_time"]]
    threads: config["create_matrix"]["create_matrix_threads"] 
    params:
        top = config["top_directory"],
        sif = config["singularity_path"],
        scripts = config["snakefile_dir"]+"scripts/",
    shell:
        """ 
        singularity exec --bind {params.top} {params.sif} python {params.scripts}create_matrix.py \
            --n {wildcards.n} \
            --meta_analysis {wildcards.meta_analysis} \
            --donor_list {input.donor_list} \
            --input {input.corr} \
            --output {output.corr} {output.pval}